{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d5d31ed-e09f-49ba-86ef-907310e1eb05",
   "metadata": {},
   "source": [
    "# **Machine learning algorithms  for groundwater potential zone mapping **\n",
    "#### *Learning Objective: Tree algorithm application for classfication *\n",
    "\n",
    "## Step 1: Import neccsary pakages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56449613-8ae2-4050-8f8f-34e6b09723fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes  import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import cohen_kappa_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f0750a-9aee-4c1c-bc73-812bf11407dd",
   "metadata": {},
   "source": [
    "## Import the ground water features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ebe3b7-a9fd-4c70-a6d4-e4fe2651ab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Addisu\\AppData\\Local\\Temp\\ipykernel_16096\\350987716.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  raw_data = pd.read_csv(file, parse_dates = ['POINT'],\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOMORPHOLOGY</th>\n",
       "      <th>GEOLOGY</th>\n",
       "      <th>DD</th>\n",
       "      <th>LD</th>\n",
       "      <th>LULC</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>SLOPE</th>\n",
       "      <th>SOIL</th>\n",
       "      <th>RF</th>\n",
       "      <th>TWI</th>\n",
       "      <th>TRI</th>\n",
       "      <th>GWPZ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POINT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.325477</td>\n",
       "      <td>4</td>\n",
       "      <td>1335.947876</td>\n",
       "      <td>8.608494</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.117109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.591102</td>\n",
       "      <td>1.897165</td>\n",
       "      <td>3</td>\n",
       "      <td>1339.761108</td>\n",
       "      <td>7.617993</td>\n",
       "      <td>0.444443</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.128686</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>0.185586</td>\n",
       "      <td>3.067638</td>\n",
       "      <td>4</td>\n",
       "      <td>1378.995850</td>\n",
       "      <td>6.364176</td>\n",
       "      <td>0.333336</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.172452</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>0.159055</td>\n",
       "      <td>1.029148</td>\n",
       "      <td>4</td>\n",
       "      <td>1309.259766</td>\n",
       "      <td>7.457202</td>\n",
       "      <td>0.555557</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.046802</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>0.047932</td>\n",
       "      <td>1.659165</td>\n",
       "      <td>4</td>\n",
       "      <td>1282.893433</td>\n",
       "      <td>10.000207</td>\n",
       "      <td>0.555552</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400561</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>0.240720</td>\n",
       "      <td>4.236006</td>\n",
       "      <td>2</td>\n",
       "      <td>1319.558472</td>\n",
       "      <td>6.887485</td>\n",
       "      <td>0.462962</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.031579</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.347756</td>\n",
       "      <td>1.029148</td>\n",
       "      <td>4</td>\n",
       "      <td>1187.568237</td>\n",
       "      <td>7.457202</td>\n",
       "      <td>0.555542</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.125304</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>0.418332</td>\n",
       "      <td>0.920517</td>\n",
       "      <td>4</td>\n",
       "      <td>1167.813477</td>\n",
       "      <td>8.496922</td>\n",
       "      <td>0.555557</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.828552</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.476153</td>\n",
       "      <td>3.347209</td>\n",
       "      <td>2</td>\n",
       "      <td>1176.781494</td>\n",
       "      <td>6.276775</td>\n",
       "      <td>0.444446</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.301506</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>0.141697</td>\n",
       "      <td>1.173371</td>\n",
       "      <td>4</td>\n",
       "      <td>1138.209839</td>\n",
       "      <td>11.558352</td>\n",
       "      <td>0.777771</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2959 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GEOMORPHOLOGY  GEOLOGY        DD  LD  LULC      NDVI    SLOPE   SOIL  \\\n",
       "POINT                                                                         \n",
       "1                  4        5  0.000000   1   118  0.132800  0.325477     4   \n",
       "2                  5        6  0.117109   1     1  0.591102  1.897165     3   \n",
       "3                  6        5  0.128686   1   118  0.185586  3.067638     4   \n",
       "4                  4        5  0.172452   1   118  0.159055  1.029148     4   \n",
       "5                  5        5  0.046802   1   118  0.047932  1.659165     4   \n",
       "...              ...      ...       ...  ..   ...       ...       ...   ...   \n",
       "2955               2        3  0.400561   3   118  0.240720  4.236006     2   \n",
       "2956               4        5  0.031579   1    45  0.347756  1.029148     4   \n",
       "2957               4        5  0.125304   1    84  0.418332  0.920517     4   \n",
       "2958               4        5  0.828552   1    45  0.476153  3.347209     2   \n",
       "2959               4        5  0.301506   1   118  0.141697  1.173371     4   \n",
       "\n",
       "                RF        TWI       TRI  GWPZ  \n",
       "POINT                                          \n",
       "1      1335.947876   8.608494  0.333328     4  \n",
       "2      1339.761108   7.617993  0.444443     3  \n",
       "3      1378.995850   6.364176  0.333336     3  \n",
       "4      1309.259766   7.457202  0.555557     3  \n",
       "5      1282.893433  10.000207  0.555552     3  \n",
       "...            ...        ...       ...   ...  \n",
       "2955   1319.558472   6.887485  0.462962     3  \n",
       "2956   1187.568237   7.457202  0.555542     4  \n",
       "2957   1167.813477   8.496922  0.555557     4  \n",
       "2958   1176.781494   6.276775  0.444446     4  \n",
       "2959   1138.209839  11.558352  0.777771     3  \n",
       "\n",
       "[2959 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1: Read and explore data\n",
    "file='E:/kidi file e/PAPERS/GWPM/nn.csv'\n",
    "raw_data = pd.read_csv(file, parse_dates = ['POINT'],\n",
    "                       index_col = 'POINT')\n",
    "df = raw_data.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c134d6a2-faa7-4cd2-a23f-41ad2264e165",
   "metadata": {},
   "source": [
    "## Data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16003392-5904-4dbd-8091-08cb676677f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Replace all -9999s with NaNs to make it easier to work with\n",
    "df.replace(to_replace=-9999, value=np.nan, inplace=True)\n",
    "# Check missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "\n",
    "# Check missing values\n",
    "df.isnull().sum()\n",
    "# Replace missing values by interpolation\n",
    "\n",
    "def replace_missing (attribute):\n",
    "    return attribute.interpolate(inplace=True)\n",
    "replace_missing(df['GEOMORPHOLOGY'])\n",
    "replace_missing(df['DD'])\n",
    "replace_missing(df['LD'])\n",
    "replace_missing(df['LULC'])\n",
    "replace_missing(df['NDVI'])\n",
    "replace_missing(df['SLOPE '])\n",
    "replace_missing(df['SOIL'])\n",
    "replace_missing(df['RF'])\n",
    "replace_missing(df['TWI'])\n",
    "replace_missing(df['TRI'])\n",
    "replace_missing(df['GWPZ'])\n",
    "replace_missing(df['GEOLOGY'])\n",
    "\n",
    "df\n",
    "\n",
    "#df.to_excel(\"C:/Users/User/Desktop/GWPM/missing out.xlsx\",index=False)\n",
    "\n",
    "# Read data from  csv files\n",
    "X = df.drop([\"GWPZ\"], axis=1)\n",
    "y = df[\"GWPZ\"]\n",
    "Input_data_features = X.values\n",
    "Input_data_labels =y.values\n",
    "\n",
    "\n",
    "# standardize input features X and output labels Y\n",
    "#scaler_standardized_X = StandardScaler()\n",
    "#Input_data_features = scaler_standardized_X.fit_transform(Input_data_features)\n",
    "\n",
    "#scaler_standardized_Y = StandardScaler()\n",
    "#Input_data_labels = scaler_standardized_Y.fit_transform(Input_data_labels)\n",
    "\n",
    "\n",
    "# Split dataset into train, validation, an test\n",
    "index_X_Train_End = int(0.7 * len(Input_data_features))\n",
    "index_X_Validation_End = int(0.9 * len(Input_data_features))\n",
    "\n",
    "X_train = Input_data_features[0: index_X_Train_End]\n",
    "X_valid = Input_data_features[index_X_Train_End: index_X_Validation_End]\n",
    "X_test = Input_data_features[index_X_Validation_End:]\n",
    "\n",
    "Y_train = Input_data_labels[0: index_X_Train_End]\n",
    "Y_valid = Input_data_labels[index_X_Train_End: index_X_Validation_End]\n",
    "Y_test = Input_data_labels[index_X_Validation_End:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c5d16-808e-4773-8958-d9a1f540c58b",
   "metadata": {},
   "source": [
    "## method 1: random forest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd1a5689-82ed-41c7-8ce5-a5c271caff4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy RandomForestClassifier:  0.8614864864864865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      0.25      0.40         4\n",
      "           3       0.81      0.84      0.83       115\n",
      "           4       0.90      0.89      0.89       177\n",
      "\n",
      "    accuracy                           0.86       296\n",
      "   macro avg       0.90      0.66      0.71       296\n",
      "weighted avg       0.86      0.86      0.86       296\n",
      "\n",
      "kappa Randomforest:  0.716693512617597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1521: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1521: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#method 1: random forest model and train it\n",
    "model_randomForest = RandomForestClassifier()\n",
    "model_randomForest.fit(X_train, Y_train)\n",
    "rfr = model_randomForest.predict(X_test)\n",
    "#print(f\"Random Forest Prediction: {rfr}\")\n",
    "print(\"Accuracy RandomForestClassifier: \", accuracy_score(Y_test, rfr))\n",
    "#print(\"precision_recall_fscore RandomForestClassifier:\",precision_recall_fscore_support(Y_test, rfr, average='weighted'))\n",
    "precision_positive = metrics.precision_score(Y_test, rfr, pos_label=1,average='micro')\n",
    "precision_negative = metrics.precision_score(Y_test, rfr, pos_label=0,average='micro') \n",
    "recall_sensitivity = metrics.recall_score(Y_test, rfr, pos_label=1,average='micro')\n",
    "recall_specificity = metrics.recall_score(Y_test, rfr, pos_label=0,average='micro')\n",
    "f1_positive = metrics.f1_score(Y_test, rfr, pos_label=1,average='micro' )\n",
    "f1_negative = metrics.f1_score(Y_test, rfr, pos_label=1,average='micro')\n",
    "print(metrics.classification_report(Y_test, rfr))\n",
    "print(\"kappa Randomforest: \",cohen_kappa_score(Y_test, rfr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05999ac1-e245-4f8c-8802-73ab0d34ebe5",
   "metadata": {},
   "source": [
    "## method:2 Gradient boosting  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd6b6fac-f8c4-4cd0-9a4c-992cd83c8436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy GradientBoostingClassifier:  0.8513513513513513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.50      0.25      0.33         4\n",
      "           3       0.81      0.80      0.81       115\n",
      "           4       0.88      0.90      0.89       177\n",
      "\n",
      "    accuracy                           0.85       296\n",
      "   macro avg       0.73      0.65      0.68       296\n",
      "weighted avg       0.85      0.85      0.85       296\n",
      "\n",
      "kappa GradientBoosting:  0.6940999624201429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1521: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1521: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#method:2gradient boosting  model and train it (-->Here I get the ValueError)\n",
    "model_gradientBoosting = GradientBoostingClassifier( )\n",
    "model_gradientBoosting.fit(X_train, Y_train)\n",
    "GBP = model_gradientBoosting.predict(X_test)\n",
    "#print(f\"Gradient Boosting Prediction: {Y_pred_gradientBoosting}\")\n",
    "print(\"Accuracy GradientBoostingClassifier: \", accuracy_score(Y_test, GBP))\n",
    "#print(\"precision_recall_fscore GradientBoostingClassifier:\",precision_recall_fscore_support(Y_test, GBP, average='weighted'))\n",
    "precision_positive = metrics.precision_score(Y_test, GBP, pos_label=1,average='micro')\n",
    "precision_negative = metrics.precision_score(Y_test, GBP, pos_label=0,average='micro') \n",
    "recall_sensitivity = metrics.recall_score(Y_test, GBP, pos_label=1,average='micro')\n",
    "recall_specificity = metrics.recall_score(Y_test, GBP, pos_label=0,average='micro')\n",
    "f1_positive = metrics.f1_score(Y_test, GBP, pos_label=1,average='micro' )\n",
    "f1_negative = metrics.f1_score(Y_test, GBP, pos_label=1,average='micro')\n",
    "print(metrics.classification_report(Y_test, GBP))\n",
    "print(\"kappa GradientBoosting: \",cohen_kappa_score(Y_test, GBP))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882050f2-d273-4ae9-bab5-30f80ddfd9c4",
   "metadata": {},
   "source": [
    "## Method 3:Decsion tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bef3e92c-3e82-4972-bd7e-c2154de02c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Decsion tree classifier  :  0.7635135135135135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.25      0.25      0.25         4\n",
      "           3       0.70      0.68      0.69       115\n",
      "           4       0.82      0.83      0.82       177\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.76       296\n",
      "   macro avg       0.44      0.44      0.44       296\n",
      "weighted avg       0.76      0.76      0.76       296\n",
      "\n",
      "kappa Decsion tree classifier:  0.5178592204770215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1521: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1521: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Method 3:Decsion tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "#print(\"DecisionTreeClassifier\")\n",
    "#print(clf.predict(X_test))\n",
    "DTC = clf.predict(X_test)\n",
    "print(\"Accuracy Decsion tree classifier  : \", accuracy_score(Y_test, DTC))\n",
    "#print(\"precision_recall_fscore Decsion tree classifier:\",precision_recall_fscore_support(Y_test, DTC, average='weighted'))\n",
    "precision_positive = metrics.precision_score(Y_test, DTC, pos_label=1,average='micro')\n",
    "precision_negative = metrics.precision_score(Y_test, DTC, pos_label=0,average='micro') \n",
    "recall_sensitivity = metrics.recall_score(Y_test, DTC, pos_label=1,average='micro')\n",
    "recall_specificity = metrics.recall_score(Y_test,  DTC, pos_label=0,average='micro')\n",
    "f1_positive = metrics.f1_score(Y_test,  DTC, pos_label=1,average='micro' )\n",
    "f1_negative = metrics.f1_score(Y_test,  DTC, pos_label=1,average='micro')\n",
    "print(metrics.classification_report(Y_test,  DTC))\n",
    "print(\"kappa Decsion tree classifier: \",cohen_kappa_score(Y_test, DTC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d72ca41-0471-4de2-8df1-85de4dab0289",
   "metadata": {},
   "source": [
    "## Method 4:  kneighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "339b79d5-d75e-4543-9be2-784ce91c1e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNeighborsClassifier :  0.7432432432432432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.33      0.25      0.29         4\n",
      "           3       0.69      0.62      0.65       115\n",
      "           4       0.78      0.84      0.81       177\n",
      "\n",
      "    accuracy                           0.74       296\n",
      "   macro avg       0.60      0.57      0.58       296\n",
      "weighted avg       0.74      0.74      0.74       296\n",
      "\n",
      "kappa KNeighbors:  0.4660210306439745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1521: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1521: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Method 4:  kneighbors classifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "#print(\"KNeighborsClassifier\")\n",
    "#print(clf.predict(X_test))\n",
    "KNC = clf.predict(X_test)\n",
    "print(\"Accuracy KNeighborsClassifier : \", accuracy_score(Y_test, KNC))\n",
    "#print(\"precision_recall_fscore KNeighborsClassifier:\",precision_recall_fscore_support(Y_test, KNC, average='weighted'))\n",
    "precision_positive = metrics.precision_score(Y_test, KNC, pos_label=1,average='micro')\n",
    "precision_negative = metrics.precision_score(Y_test, KNC, pos_label=0,average='micro') \n",
    "recall_sensitivity = metrics.recall_score(Y_test, KNC, pos_label=1,average='micro')\n",
    "recall_specificity = metrics.recall_score(Y_test,  KNC, pos_label=0,average='micro')\n",
    "f1_positive = metrics.f1_score(Y_test,  KNC, pos_label=1,average='micro' )\n",
    "f1_negative = metrics.f1_score(Y_test,  KNC, pos_label=1,average='micro')\n",
    "print(metrics.classification_report(Y_test,  KNC))\n",
    "print(\"kappa KNeighbors: \",cohen_kappa_score(Y_test, KNC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5f13f-c157-4306-81ef-4377f371b811",
   "metadata": {},
   "source": [
    "## Method 5:Lineardiscriminatanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce5df51c-7ac0-4e99-bd10-2b30ed755b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Lineardiscriminatanalysis :  0.6452702702702703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.14      0.25      0.18         4\n",
      "           3       0.63      0.37      0.47       115\n",
      "           4       0.69      0.83      0.76       177\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.65       296\n",
      "   macro avg       0.37      0.36      0.35       296\n",
      "weighted avg       0.66      0.65      0.64       296\n",
      "\n",
      "kappa Lineardiscrimina:  0.26427421645677496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1521: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1521: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train, Y_train)\n",
    "LDA = clf.predict(X_test)\n",
    "print(\"Accuracy Lineardiscriminatanalysis : \", accuracy_score(Y_test, LDA))\n",
    "#print(\"precision_recall_fscore Lineardiscriminatanalysis:\",precision_recall_fscore_support(Y_test, LDA, average='weighted'))\n",
    "precision_positive = metrics.precision_score(Y_test, LDA, pos_label=1,average='micro')\n",
    "precision_negative = metrics.precision_score(Y_test, LDA, pos_label=0,average='micro') \n",
    "recall_sensitivity = metrics.recall_score(Y_test, LDA, pos_label=1,average='micro')\n",
    "recall_specificity = metrics.recall_score(Y_test,  LDA, pos_label=0,average='micro')\n",
    "f1_positive = metrics.f1_score(Y_test,  LDA, pos_label=1,average='micro' )\n",
    "f1_negative = metrics.f1_score(Y_test,  LDA, pos_label=1,average='micro')\n",
    "print(metrics.classification_report(Y_test,  LDA))\n",
    "print(\"kappa Lineardiscrimina: \",cohen_kappa_score(Y_test, LDA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb29e5c-7826-4e34-9cf8-cd3ac4da2a94",
   "metadata": {},
   "source": [
    "## #Method 6:GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4ac9065-bfdd-43cf-b1a9-87f297dfe8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy GaussianNB:  0.6351351351351351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.10      0.75      0.18         4\n",
      "           3       0.71      0.39      0.51       115\n",
      "           4       0.77      0.79      0.78       177\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.64       296\n",
      "   macro avg       0.40      0.48      0.37       296\n",
      "weighted avg       0.74      0.64      0.67       296\n",
      "\n",
      "kappa GaussianNB:  0.33695607085079027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1521: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1521: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "GANB = clf.predict(X_test)\n",
    "print(\"Accuracy GaussianNB: \", accuracy_score(Y_test, GANB))\n",
    "#print(\"precision_recall_fscore GaussianNB:\",precision_recall_fscore_support(Y_test, GANB, average='weighted'))\n",
    "precision_positive = metrics.precision_score(Y_test, GANB, pos_label=1,average='micro')\n",
    "precision_negative = metrics.precision_score(Y_test, GANB, pos_label=0,average='micro') \n",
    "recall_sensitivity = metrics.recall_score(Y_test, GANB, pos_label=1,average='micro')\n",
    "recall_specificity = metrics.recall_score(Y_test,  GANB, pos_label=0,average='micro')\n",
    "f1_positive = metrics.f1_score(Y_test,  GANB, pos_label=1,average='micro' )\n",
    "f1_negative = metrics.f1_score(Y_test, GANB, pos_label=1,average='micro')\n",
    "print(metrics.classification_report(Y_test,  GANB))\n",
    "print(\"kappa GaussianNB: \",cohen_kappa_score(Y_test, GANB))      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eba38c-46eb-4414-99bc-f5b2d4a9c620",
   "metadata": {},
   "source": [
    "## Method 7:SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290b0f85-f12a-423a-82ef-23a505927aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Addisu\\AppData\\Local\\Temp\\ipykernel_16096\\1956935436.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  raw_data = pd.read_csv(file, parse_dates = ['POINT'],\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'B'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'B'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m replace_missing(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGWPZ\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     37\u001b[0m replace_missing(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGEOLOGY\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 38\u001b[0m replace_missing(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     39\u001b[0m df\n\u001b[0;32m     41\u001b[0m df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/User/Desktop/GWPM/missing out.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\jupyterenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'B'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "#Method 7:SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, Y_train)\n",
    "SVC = clf.predict(X_test)\n",
    "print(\"Accuracy Support Vector Classifier: \", accuracy_score(Y_test, SVC))\n",
    "#print(\"precision_recall_fscore Support Vector Classifier:\",precision_recall_fscore_support(Y_test, SVC, average='weighted'))\n",
    "precision_positive = metrics.precision_score(Y_test, SVC, pos_label=1,average='micro')\n",
    "precision_negative = metrics.precision_score(Y_test, SVC, pos_label=0,average='micro') \n",
    "recall_sensitivity = metrics.recall_score(Y_test, SVC, pos_label=1,average='micro')\n",
    "recall_specificity = metrics.recall_score(Y_test,  SVC, pos_label=0,average='micro')\n",
    "f1_positive = metrics.f1_score(Y_test,  SVC, pos_label=1,average='micro' )\n",
    "f1_negative = metrics.f1_score(Y_test, SVC, pos_label=1,average='micro')\n",
    "print(metrics.classification_report(Y_test,  SVC))\n",
    "print(\"kappa SVC: \",cohen_kappa_score(Y_test, SVC))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_future(rfr,G,D,K,LDA,GA,KNC, Y_test):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    range_futurel = len(rfr)\n",
    "    range_future2=len(GBP)\n",
    "    range_future3=len(DTC)\n",
    "    range_future4=len(KNC)\n",
    "    range_future5=len(LDA)\n",
    "    range_future6=len(GANB)\n",
    "    range_future7=len(SVC)\n",
    "    \n",
    "    plt.plot(np.arange( range_futurel), np.array(Y_test), label='True Future')     \n",
    "    plt.plot(np.arange( range_futurel),np.array(rfr),label='Random forest prediction')\n",
    "    plt.plot(np.arange( range_future2),np.array(GBP),label='gradientBoosting')\n",
    "    plt.plot(np.arange( range_future2),np.array(DTC),label='Decsion tree classifier')\n",
    "    plt.plot(np.arange( range_future2),np.array(KNC),label='kneighbors classifier')\n",
    "    plt.plot(np.arange( range_future2),np.array(LDA),label='Linear discriminat analysis')\n",
    "    plt.plot(np.arange( range_future2),np.array(GANB),label='GaussianNB')\n",
    "    plt.plot(np.arange( range_future2),np.array(KNC),label='Support Vector Classifier')\n",
    "\n",
    "\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.xlabel('POINT')\n",
    "    plt.ylabel('Bore hole distribution')\n",
    "plot_future(rfr,GBP,DTC,KNC,LDA,GANB,KNC, Y_test)\n",
    "#plot_future(prediction_lstm, y_test)\n",
    "#plot_future(, y_test)\n",
    "\n",
    "results_path = 'GWPZ.png'\n",
    "    #print(results_path)\n",
    "plt.savefig(results_path, dpi=600)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ef2e1b-e702-4edc-963d-4246c5a13e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
